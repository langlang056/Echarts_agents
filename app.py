"""
LocalInsight - Intelligent Local Data Analyst

A zero-code, privacy-safe, interactive data analysis tool powered by AgentScope.
Upload CSV/Excel files and ask questions to get interactive ECharts visualizations
and business insights.
"""

import os
import sys
import asyncio
import streamlit as st
import traceback
from pathlib import Path
from datetime import datetime

from agentscope.message import Msg
from agents import create_data_engineer_agent, create_business_analyst_agent


# Page configuration
st.set_page_config(
    page_title="LocalInsight - æ™ºèƒ½æ•°æ®åˆ†æå¸ˆ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .analysis-box {
        background-color: #f0f8ff;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
    }
    .stAlert {
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)


def initialize_session_state():
    """Initialize Streamlit session state variables."""
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'uploaded_file_path' not in st.session_state:
        st.session_state.uploaded_file_path = None
    if 'data_engineer' not in st.session_state:
        st.session_state.data_engineer = None
    if 'business_analyst' not in st.session_state:
        st.session_state.business_analyst = None
    if 'agents_initialized' not in st.session_state:
        st.session_state.agents_initialized = False


def initialize_agents(model_type: str, api_key: str, model_name: str = None):
    """Initialize the two agents with given configuration.

    Args:
        model_type (str): "dashscope" or "openai"
        api_key (str): API key for the model provider
        model_name (str): Optional model name override
    """
    try:
        with st.spinner("ğŸ¤– æ­£åœ¨åˆå§‹åŒ– AI æ™ºèƒ½ä½“..."):
            # Create Data Engineer Agent
            st.session_state.data_engineer = create_data_engineer_agent(
                model_type=model_type,
                api_key=api_key,
                model_name=model_name,
                temperature=0.7,
                max_iters=10
            )

            # Create Business Analyst Agent
            st.session_state.business_analyst = create_business_analyst_agent(
                model_type=model_type,
                api_key=api_key,
                model_name=model_name,
                temperature=0.8
            )

            st.session_state.agents_initialized = True
            st.success("âœ… AI æ™ºèƒ½ä½“åˆå§‹åŒ–æˆåŠŸï¼")

    except Exception as e:
        st.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        st.session_state.agents_initialized = False
        raise


async def run_analysis_pipeline(user_question: str, file_path: str) -> dict:
    """Run the two-agent analysis pipeline.

    Args:
        user_question (str): User's question about the data
        file_path (str): Path to the uploaded data file

    Returns:
        dict: Contains 'analysis' (str), 'engineer_log' (str), and 'success' (bool)
    """
    try:
        # Ensure temp directory exists
        os.makedirs("./temp", exist_ok=True)

        # Step 1: Data Engineer Agent processes data and creates visualization
        st.info("ğŸ”§ æ•°æ®å·¥ç¨‹å¸ˆæ­£åœ¨å¤„ç†æ•°æ®...")

        engineer_msg = Msg(
            name="user",
            content=f"""æ•°æ®æ–‡ä»¶è·¯å¾„: {file_path}

ç”¨æˆ·é—®é¢˜: {user_question}

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®Œæˆä»»åŠ¡:
1. ä½¿ç”¨ read_data_schema å·¥å…·äº†è§£æ•°æ®ç»“æ„
2. æ ¹æ®ç”¨æˆ·éœ€æ±‚ç¼–å†™ Python ä»£ç å¤„ç†æ•°æ®å¹¶ç”Ÿæˆ Pyecharts å¯è§†åŒ–
3. ä¿å­˜å›¾è¡¨ä¸º ./temp/visual_result.html
4. ä½¿ç”¨ print() è¾“å‡ºå…³é”®ç»Ÿè®¡æŒ‡æ ‡
5. ä½¿ç”¨ validate_html_output éªŒè¯æ–‡ä»¶ç”ŸæˆæˆåŠŸ
""",
            role="user"
        )

        # Call Data Engineer Agent
        engineer_response = await st.session_state.data_engineer(engineer_msg)

        # Extract execution log from engineer's response
        # The log contains all print() outputs from executed code
        engineer_log = extract_execution_log(engineer_response)

        # Check if visualization file was created
        viz_file_path = "./temp/visual_result.html"
        if not os.path.exists(viz_file_path):
            return {
                'analysis': f"**é”™è¯¯**: æ•°æ®å·¥ç¨‹å¸ˆæœªèƒ½ç”Ÿæˆå¯è§†åŒ–æ–‡ä»¶ã€‚\n\nå·¥ç¨‹å¸ˆè¾“å‡º:\n{engineer_response.content}",
                'engineer_log': engineer_log,
                'success': False
            }

        # Step 2: Business Analyst Agent analyzes the results
        st.info("ğŸ“Š å•†ä¸šåˆ†æå¸ˆæ­£åœ¨åˆ†ææ•°æ®...")

        analyst_msg = Msg(
            name="engineer",
            content=f"""ç”¨æˆ·é—®é¢˜: {user_question}

æ•°æ®å·¥ç¨‹å¸ˆæ‰§è¡Œæ—¥å¿—:
{engineer_log}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œä¸ºç”¨æˆ·ç”Ÿæˆé€šä¿—æ˜“æ‡‚çš„å•†ä¸šåˆ†ææŠ¥å‘Šã€‚
""",
            role="assistant"
        )

        # Call Business Analyst Agent
        analyst_response = await st.session_state.business_analyst(analyst_msg)

        return {
            'analysis': analyst_response.content,
            'engineer_log': engineer_log,
            'success': True
        }

    except Exception as e:
        error_msg = f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:\n\n{str(e)}\n\n{traceback.format_exc()}"
        return {
            'analysis': error_msg,
            'engineer_log': "",
            'success': False
        }


def extract_execution_log(engineer_msg: Msg) -> str:
    """Extract execution log (print outputs) from engineer's response.

    Args:
        engineer_msg (Msg): Response message from Data Engineer Agent

    Returns:
        str: Extracted execution log
    """
    content = engineer_msg.content

    # Try to extract content between "=== Output ===" markers
    if "=== Output ===" in content:
        parts = content.split("=== Output ===")
        if len(parts) > 1:
            # Get everything after the first marker
            log_part = parts[1].split("===")[0].strip()
            return log_part

    # Fallback: return full content
    return content


def display_chat_message(role: str, content: str):
    """Display a chat message with appropriate styling.

    Args:
        role (str): "user" or "assistant"
        content (str): Message content
    """
    with st.chat_message(role):
        st.markdown(content)


def main():
    """Main Streamlit application."""
    initialize_session_state()

    # Header
    st.markdown('<div class="main-header">ğŸ“Š LocalInsight</div>', unsafe_allow_html=True)
    st.markdown(
        '<div class="sub-header">æ™ºèƒ½æœ¬åœ°æ•°æ®åˆ†æå¸ˆ - é›¶ä»£ç  Â· éšç§å®‰å…¨ Â· äº¤äº’å¼å¯è§†åŒ–</div>',
        unsafe_allow_html=True
    )

    # Sidebar configuration
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")

        # Model provider selection
        model_type = st.selectbox(
            "é€‰æ‹©æ¨¡å‹æä¾›å•†",
            ["dashscope", "openai"],
            help="DashScope (é€šä¹‰åƒé—®) æˆ– OpenAI (GPT)"
        )

        # API Key input
        api_key_label = "DashScope API Key" if model_type == "dashscope" else "OpenAI API Key"
        api_key_env = "DASHSCOPE_API_KEY" if model_type == "dashscope" else "OPENAI_API_KEY"

        # Try to get API key from environment
        default_api_key = os.environ.get(api_key_env, "")

        api_key = st.text_input(
            api_key_label,
            value=default_api_key,
            type="password",
            help=f"è¾“å…¥ä½ çš„ {api_key_label}ï¼Œæˆ–åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® {api_key_env}"
        )

        # Model name selection
        if model_type == "dashscope":
            model_name = st.selectbox(
                "é€‰æ‹©æ¨¡å‹",
                ["qwen-max", "qwen-plus", "qwen-turbo"],
                help="æ¨èä½¿ç”¨ qwen-max ä»¥è·å¾—æœ€ä½³æ•ˆæœ"
            )
        else:
            model_name = st.selectbox(
                "é€‰æ‹©æ¨¡å‹",
                ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"],
                help="æ¨èä½¿ç”¨ gpt-4 ä»¥è·å¾—æœ€ä½³æ•ˆæœ"
            )

        # Initialize agents button
        if st.button("ğŸš€ åˆå§‹åŒ–æ™ºèƒ½ä½“", use_container_width=True):
            if not api_key:
                st.error(f"è¯·å…ˆè¾“å…¥ {api_key_label}ï¼")
            else:
                # Set environment variable
                os.environ[api_key_env] = api_key
                initialize_agents(model_type, api_key, model_name)

        # Status indicator
        if st.session_state.agents_initialized:
            st.success("âœ… æ™ºèƒ½ä½“å·²å°±ç»ª")
        else:
            st.warning("âš ï¸ è¯·å…ˆåˆå§‹åŒ–æ™ºèƒ½ä½“")

        st.divider()

        # File upload
        st.header("ğŸ“ ä¸Šä¼ æ•°æ®")
        uploaded_file = st.file_uploader(
            "é€‰æ‹© CSV æˆ– Excel æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            help="æ”¯æŒ CSV å’Œ Excel æ ¼å¼"
        )

        if uploaded_file is not None:
            # Save uploaded file
            os.makedirs("./temp", exist_ok=True)

            file_ext = os.path.splitext(uploaded_file.name)[1]
            file_path = f"./temp/data{file_ext}"

            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            st.session_state.uploaded_file_path = file_path

            st.success(f"âœ… å·²ä¸Šä¼ : {uploaded_file.name}")
            st.info(f"æ–‡ä»¶å¤§å°: {uploaded_file.size / 1024:.2f} KB")

        st.divider()

        # Clear chat button
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True):
            st.session_state.messages = []
            if st.session_state.data_engineer:
                st.session_state.data_engineer.memory.clear()
            if st.session_state.business_analyst:
                st.session_state.business_analyst.memory.clear()
            st.rerun()

        # About section
        st.divider()
        st.markdown("""
        ### å…³äº LocalInsight

        **ç‰¹ç‚¹**:
        - ğŸ”’ **éšç§å®‰å…¨**: æ•°æ®å®Œå…¨æœ¬åœ°å¤„ç†
        - ğŸ¨ **äº¤äº’å¼å›¾è¡¨**: åŸºäº ECharts çš„åŠ¨æ€å¯è§†åŒ–
        - ğŸ¤– **AI é©±åŠ¨**: åŒæ™ºèƒ½ä½“åä½œåˆ†æ
        - ğŸ’¬ **å¯¹è¯å¼**: è‡ªç„¶è¯­è¨€æé—®

        **æŠ€æœ¯æ ˆ**:
        - AgentScope (å¤šæ™ºèƒ½ä½“æ¡†æ¶)
        - Pyecharts (å¯è§†åŒ–)
        - Streamlit (Webç•Œé¢)
        """)

    # Main content area
    if not st.session_state.agents_initialized:
        st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§é…ç½®å¹¶åˆå§‹åŒ–æ™ºèƒ½ä½“")
        st.markdown("""
        ### å¿«é€Ÿå¼€å§‹

        1. **é…ç½®æ¨¡å‹**
           - é€‰æ‹©æ¨¡å‹æä¾›å•† (DashScope æˆ– OpenAI)
           - è¾“å…¥ API Key
           - é€‰æ‹©æ¨¡å‹ç‰ˆæœ¬

        2. **åˆå§‹åŒ–æ™ºèƒ½ä½“**
           - ç‚¹å‡»"åˆå§‹åŒ–æ™ºèƒ½ä½“"æŒ‰é’®

        3. **ä¸Šä¼ æ•°æ®**
           - ä¸Šä¼  CSV æˆ– Excel æ–‡ä»¶

        4. **å¼€å§‹åˆ†æ**
           - åœ¨ä¸‹æ–¹è¾“å…¥æ¡†æå‡ºé—®é¢˜
           - AI ä¼šè‡ªåŠ¨ç”Ÿæˆå¯è§†åŒ–å’Œåˆ†ææŠ¥å‘Š

        ### ç¤ºä¾‹é—®é¢˜

        - "åˆ†æå„å­£åº¦çš„é”€å”®è¶‹åŠ¿"
        - "å¯¹æ¯”ä¸åŒäº§å“ç±»åˆ«çš„é”€å”®é¢"
        - "æ‰¾å‡ºé”€å”®é¢æœ€é«˜çš„å‰5ä¸ªåœ°åŒº"
        - "å±•ç¤ºæ¯æœˆæ”¶å…¥çš„å˜åŒ–æƒ…å†µ"
        - "åˆ†æå®¢æˆ·å¹´é¾„åˆ†å¸ƒ"
        """)
        return

    if st.session_state.uploaded_file_path is None:
        st.info("ğŸ‘ˆ è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        return

    # Display chat history
    for message in st.session_state.messages:
        display_chat_message(message["role"], message["content"])

    # Chat input
    user_question = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")

    if user_question:
        # Add user message to chat
        st.session_state.messages.append({"role": "user", "content": user_question})
        display_chat_message("user", user_question)

        # Run analysis pipeline
        with st.spinner("ğŸ¤” AI æ­£åœ¨åˆ†ææ•°æ®..."):
            try:
                # Run async pipeline
                result = asyncio.run(run_analysis_pipeline(
                    user_question,
                    st.session_state.uploaded_file_path
                ))

                if result['success']:
                    # Display visualization
                    viz_file_path = "./temp/visual_result.html"
                    if os.path.exists(viz_file_path):
                        st.markdown("### ğŸ“Š æ•°æ®å¯è§†åŒ–")
                        with open(viz_file_path, 'r', encoding='utf-8') as f:
                            html_content = f.read()
                        st.components.v1.html(html_content, height=600, scrolling=True)

                    # Display analysis
                    st.markdown("### ğŸ“ˆ åˆ†ææŠ¥å‘Š")
                    st.markdown(f'<div class="analysis-box">{result["analysis"]}</div>',
                               unsafe_allow_html=True)

                    # Add assistant message to chat
                    assistant_message = f"### ğŸ“Š æ•°æ®å¯è§†åŒ–\n\nå·²ç”Ÿæˆäº¤äº’å¼å›¾è¡¨ï¼ˆè¯·æŸ¥çœ‹ä¸Šæ–¹ï¼‰\n\n### ğŸ“ˆ åˆ†ææŠ¥å‘Š\n\n{result['analysis']}"
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": assistant_message
                    })

                    # Optional: Show engineer log in expander
                    if result['engineer_log']:
                        with st.expander("ğŸ” æŸ¥çœ‹æŠ€æœ¯æ—¥å¿—"):
                            st.code(result['engineer_log'], language="text")

                else:
                    # Error occurred
                    st.error("åˆ†æå¤±è´¥ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯")
                    st.code(result['analysis'], language="text")

                    # Add error message to chat
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": f"âŒ åˆ†æå¤±è´¥\n\n{result['analysis']}"
                    })

            except Exception as e:
                error_msg = f"å‘ç”Ÿé”™è¯¯: {str(e)}\n\n{traceback.format_exc()}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": f"âŒ å‘ç”Ÿé”™è¯¯\n\n{error_msg}"
                })


if __name__ == "__main__":
    main()
